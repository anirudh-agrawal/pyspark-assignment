{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, Row \n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"WeatherDataAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-10-0-1-11.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>WeatherDataAnalysis</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd2d440d510>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load WeatherStations Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe Schema\n",
    "weatherStationsSchema = T.StructType([\n",
    "    T.StructField(\"State\",T.StringType()),\n",
    "    T.StructField(\"District\",T.StringType()),\n",
    "    T.StructField(\"Latitude\",T.DoubleType()),\n",
    "    T.StructField(\"Longitude\",T.DoubleType()),\n",
    "    T.StructField(\"StationID\",T.StringType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "weatherStations = spark.read.load(path = \"Datasets/Output/WeatherStationsId.csv\",\n",
    "                                  format = \"csv\",header=True,\n",
    "                                  schema = weatherStationsSchema,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State: string (nullable = true)\n",
      " |-- District: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- StationID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check Schema\n",
    "weatherStations.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+------------------+---------+---------+\n",
      "|          State|      District|          Latitude|Longitude|StationID|\n",
      "+---------------+--------------+------------------+---------+---------+\n",
      "|      TELANGANA|      NALGONDA|  16.3920001983643|   79.375|   164794|\n",
      "|          BIHAR|CHAMPARAN.WEST|  27.3199996948242|  83.4375|   273834|\n",
      "|          BIHAR|   MUZAFFARPUR|  25.4466991424561|  85.3125|   254853|\n",
      "|          BIHAR|    SAMASTIPUR|  25.4466991424561|  85.3125|   254853|\n",
      "|        GUJARAT|     AHMEDABAD|  22.9487991333008|     72.5|   229725|\n",
      "|      KARNATAKA|     BAGALKOTE|  16.0797996520996|   75.625|   161756|\n",
      "|      KARNATAKA|BANGALORE URBA|12.957500457763699|     77.5|   130775|\n",
      "|         KERALA|        IDUKKI|10.147399902343802|  77.1875|   101772|\n",
      "|MADHAYA PRADESH|   NARSINGHPUR|  7.02514982223511|   79.375|    70794|\n",
      "|    MAHARASHTRA|    AHMEDNAGAR|   18.577600479126|  75.3125|   186753|\n",
      "|    MAHARASHTRA|       YEOTMAL|  20.1387996673584|  78.4375|   201784|\n",
      "|         ORISSA|       BHADRAK|  21.3876991271973|    86.25|   214863|\n",
      "|         PUNJAB|      LUDHIANA|  30.4423007965088|  75.3125|   304753|\n",
      "|      RAJASTHAN|        BARMER|  25.4466991424561|  72.1875|   254722|\n",
      "|      TAMILNADU|       VELLORE|   12.645299911499|  79.0625|   126791|\n",
      "|  UTTAR PRADESH|       MATHURA|  27.3199996948242|  77.1875|   273772|\n",
      "|  UTTAR PRADESH|     MORADABAD|  29.1933994293213|  78.4375|   292784|\n",
      "|  UTTAR PRADESH|     SHRAWASTI|  27.3199996948242|  81.5625|   273816|\n",
      "|    WEST BENGAL|       BANKURA|23.260999679565398|  87.1875|   233872|\n",
      "|    WEST BENGAL|    JALPAIGURI|    26.38330078125|   89.375|   264894|\n",
      "+---------------+--------------+------------------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check Data\n",
    "weatherStations.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load WeatherData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe Schema\n",
    "weatherDataSchema = T.StructType([\n",
    "    T.StructField(\"Date\",T.DateType()),\n",
    "    T.StructField(\"MaxTemperature\",T.DoubleType()),\n",
    "    T.StructField(\"MinTemperature\",T.DoubleType()),\n",
    "    T.StructField(\"Precipitation\",T.DoubleType()),\n",
    "    T.StructField(\"RelativeHumidity\",T.DoubleType()),\n",
    "    T.StructField(\"StationId\",T.StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "weatherData = spark.read.load(\"Datasets/Output/WeatherData.csv\",\n",
    "                             format=\"csv\", schema=weatherDataSchema,\n",
    "                             header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- MaxTemperature: double (nullable = true)\n",
      " |-- MinTemperature: double (nullable = true)\n",
      " |-- Precipitation: double (nullable = true)\n",
      " |-- RelativeHumidity: double (nullable = true)\n",
      " |-- StationId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check schema\n",
    "weatherData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+--------------+-------------+-----------------+---------+\n",
      "|      Date|   MaxTemperature|MinTemperature|Precipitation| RelativeHumidity|StationId|\n",
      "+----------+-----------------+--------------+-------------+-----------------+---------+\n",
      "|2000-01-01|           -5.726|       -16.477|  0.181961028|0.888501860192614|   323772|\n",
      "|2000-01-02|-6.11599999999999|       -24.217| 0.0102996864|0.902365760303462|   323772|\n",
      "|2000-01-03|-5.70600000000002|       -16.677| 0.1235961792|0.842162583304904|   323772|\n",
      "|2000-01-04|-6.10000000000002|       -17.362|  0.401687496|0.866002168607601|   323772|\n",
      "|2000-01-05|-7.59899999999999|        -18.76| 0.5081174424|0.817787436720489|   323772|\n",
      "|2000-01-06|           -5.529|       -16.434|  0.065231316|0.810127597488599|   323772|\n",
      "|2000-01-07|           -6.815|       -23.009|  3.738789252|0.830508587510486|   323772|\n",
      "|2000-01-08|-6.96899999999999|       -11.726|  4.318999704| 0.90915788839414|   323772|\n",
      "|2000-01-09|          -10.712|       -14.443|  12.03003216|0.922304070388122|   323772|\n",
      "|2000-01-10|          -10.038|       -17.205|  1.548385596|0.840453232817701|   323772|\n",
      "|2000-01-11|          -11.455|       -13.562|  21.87309564|0.926200548399611|   323772|\n",
      "|2000-01-12|          -11.123|       -14.183|   17.4373596|0.931560574126619|   323772|\n",
      "|2000-01-13|          -12.512|       -17.106|  11.05327656|0.913713362142371|   323772|\n",
      "|2000-01-14|          -14.812|       -21.523| 1.7337805848|0.815723201748253|   323772|\n",
      "|2000-01-15|          -15.651|       -23.803| 0.6042480768|0.752737850691254|   323772|\n",
      "|2000-01-16|          -13.245|       -26.595|   0.00686646|0.662573947277053|   323772|\n",
      "|2000-01-17|-8.76799999999997|        -25.36|  1.362991284|0.719697705166061|   323772|\n",
      "|2000-01-18|-5.87799999999999|       -12.123|  7.487872992|0.863469250628939|   323772|\n",
      "|2000-01-19|           -7.786|       -23.568| 4.3464710088|0.840517947070805|   323772|\n",
      "|2000-01-20|-7.42099999999999|       -23.677|          0.0|0.682354534789134|   323772|\n",
      "+----------+-----------------+--------------+-------------+-----------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check data\n",
    "weatherData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6852760"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check number of records\n",
    "weatherData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check the number of districts and stations mapped to each of them\n",
    "tempDF = weatherStations.groupBy(\"State\",\"District\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+-----+\n",
      "|         State|    District|count|\n",
      "+--------------+------------+-----+\n",
      "|     KARNATAKA|    GULBARGA|   13|\n",
      "|ANDHRA PRADESH|   ANANTAPUR|   12|\n",
      "|   MAHARASHTRA|       POONA|   11|\n",
      "|ANDHRA PRADESH|     NELLORE|   11|\n",
      "|     KARNATAKA|     BELGAUM|   11|\n",
      "|     KARNATAKA|KANARA NORTH|   10|\n",
      "|     KARNATAKA|     SHIMOGA|   10|\n",
      "|ANDHRA PRADESH|     CHITTOR|   10|\n",
      "|   MAHARASHTRA|    SHOLAPUR|   10|\n",
      "|     KARNATAKA|   BAGALKOTE|    9|\n",
      "|     KARNATAKA|      TUMKUR|    9|\n",
      "|ANDHRA PRADESH|    CUDDAPAH|    9|\n",
      "|       GUJARAT|       KUTCH|    9|\n",
      "|     KARNATAKA|     RAICHUR|    9|\n",
      "|     KARNATAKA|      HASSAN|    9|\n",
      "|     TELANGANA|    ADILABAD|    9|\n",
      "|   MAHARASHTRA|  AHMEDNAGAR|    9|\n",
      "|ANDHRA PRADESH|     KURNOOL|    8|\n",
      "|        ORISSA|  MAYURBHANJ|    8|\n",
      "|       GUJARAT|   AHMEDABAD|    8|\n",
      "+--------------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Listing stations with most stations\n",
    "tempDF.orderBy(F.desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------+-----------------+\n",
      "|summary|               State|     District|            count|\n",
      "+-------+--------------------+-------------+-----------------+\n",
      "|  count|                 535|          535|              535|\n",
      "|   mean|                null|         null|3.633644859813084|\n",
      "| stddev|                null|         null| 2.14379794964921|\n",
      "|    min|ANDAMAN AND NICOB...|24 PARGANAS N|                1|\n",
      "|    max|         WEST BENGAL|      YEOTMAL|               13|\n",
      "+-------+--------------------+-------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tempDF.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data at district level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/pandas/functions.py:386: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  \"in the future releases. See SPARK-28264 for more details.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#UDF for generating list of StationID for each District\n",
    "@F.pandas_udf(returnType=T.ArrayType(T.StringType()),functionType=F.PandasUDFType.GROUPED_AGG)\n",
    "def genList(data):\n",
    "     return list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "districtGrouped = (weatherStations\n",
    "                   .groupBy(\"State\",\"District\")\n",
    "                   .agg(genList(\"StationID\").alias(\"StationIDs\"))\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------+--------------------+\n",
      "|            State|       District|          StationIDs|\n",
      "+-----------------+---------------+--------------------+\n",
      "|          GUJARAT|      PORBANDAR|     [70794, 214694]|\n",
      "|        RAJASTHAN| SAWAI MADHOPUR|[264766, 254763, ...|\n",
      "|        TAMILNADU|     THIRUVARUR|    [105794, 101794]|\n",
      "|      WEST BENGAL|    COOCH BEHAR|[261884, 261894, ...|\n",
      "|          GUJARAT|  BULSAR/VALSAD|[205731, 201731, ...|\n",
      "|      MAHARASHTRA|      NANDURBAR|[211734, 214744, ...|\n",
      "|        TAMILNADU|     VILLUPURAM|[114784, 114791, ...|\n",
      "|        TAMILNADU|     COIMBATORE|[105772, 111766, ...|\n",
      "|    UTTAR PRADESH|KHERI LAKHIMPUR|[276800, 279806, ...|\n",
      "|            ASSAM|         CACHAR|[245925, 245931, ...|\n",
      "|       CHATISGARH|           DURG|[205800, 214813, ...|\n",
      "| HIMACHAL PRADESH|       BILASPUR|[311766, 314763, ...|\n",
      "|        KARNATAKA|        RAICHUR|[164766, 161772, ...|\n",
      "|  MADHAYA PRADESH|          SAGAR|[233791, 236794, ...|\n",
      "|       PUDUCHERRY|     PUDUCHERRY|    [105794, 114794]|\n",
      "|    UTTAR PRADESH|       VARANASI|    [251831, 251825]|\n",
      "|      MAHARASHTRA|         NAGPUR|[211791, 211784, ...|\n",
      "|        TAMILNADU|       NILGIRIS|[114763, 111766, ...|\n",
      "|ARUNACHAL PRADESH|     WEST SIANG|[283941, 279944, ...|\n",
      "|            BIHAR|      SITAMARHI|            [264853]|\n",
      "+-----------------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "districtGrouped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each district we need a summary of the data for every day in the data.<br>\n",
    "A good approach will be use mean value of each variable across the stations mapped to the district.  \n",
    "Another approach can be to use the median value of each variable across the stations mapped to the district. This approach will allow us to avoid affect of any possible outliers. \n",
    "\n",
    "We will use median value for _MinTemperature_ and _MaxTemperature_ and mean values for _Precipitation_ and _RelativeHumidity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(T.DoubleType(),F.PandasUDFType.GROUPED_AGG)\n",
    "def median(data):\n",
    "    return data.median()\n",
    "\n",
    "@F.pandas_udf(T.DoubleType(),F.PandasUDFType.GROUPED_AGG)\n",
    "def mean(data):\n",
    "    return data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDailySummary(stationIds):\n",
    "    summaryData = (weatherData.filter(F.col(\"StationId\").isin(stationIds))\n",
    "                   .groupBy(\"Date\")\n",
    "                   .agg(median(\"MinTemperature\"),\n",
    "                        median(\"MaxTemperature\"),\n",
    "                        mean(\"Precipitation\"),\n",
    "                        mean(\"RelativeHumidity\")))\n",
    "    return summaryData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1 runs\n",
      "Completed 26 runs\n",
      "Completed 51 runs\n",
      "Completed 76 runs\n",
      "Completed 101 runs\n",
      "Completed 126 runs\n",
      "Completed 151 runs\n",
      "Completed 176 runs\n",
      "Completed 201 runs\n",
      "Completed 226 runs\n",
      "Completed 251 runs\n",
      "Completed 276 runs\n",
      "Completed 301 runs\n",
      "Completed 326 runs\n",
      "Completed 351 runs\n",
      "Completed 376 runs\n",
      "Completed 401 runs\n",
      "Completed 426 runs\n",
      "Completed 451 runs\n",
      "Completed 476 runs\n",
      "Completed 501 runs\n",
      "Completed 526 runs\n",
      "1281.452843427658\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "districtsGroupedPDF = districtGrouped.toPandas()\n",
    "\n",
    "for index in range(len(districtsGroupedPDF)):\n",
    "    state,district,stationIds = districtsGroupedPDF.iloc[index]\n",
    "    #print(state,district,stationIds)\n",
    "    ( generateDailySummary(stationIds)\n",
    "        .select(\"Date\",\n",
    "            F.col(\"median(MinTemperature)\").alias(\"MinTemperature\"),\n",
    "            F.col(\"median(MaxTemperature)\").alias(\"MaxTemperature\"),\n",
    "            F.col(\"mean(Precipitation)\").alias(\"Precipitation\"),\n",
    "            F.col(\"mean(RelativeHumidity)\").alias(\"RelativeHumidity\"))\n",
    "        .withColumn(\"State\",F.lit(state))\n",
    "        .withColumn(\"District\",F.lit(district))\n",
    "        .write.csv(path = \"Datasets/Output/WeatherDistrictData.csv\",\n",
    "                 mode=\"append\",header=True))\n",
    "    if index%25==0:\n",
    "        print(\"Completed \"+str(index+1)+\" runs\")\n",
    "print(time.time()-starttime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
